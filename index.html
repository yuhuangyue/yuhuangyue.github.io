<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jon Barron</title>

    <meta name="author" content="Huangyue Yu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Huangyue Yu
                </p>
                <p>
		            I am a research engineer at the <a href="https://www.bigai.ai/">BIGAI</a>, General Vision Lab, focusing on 3D scene understanding, 3D scene generation, and embodied intelligence.
                    My work aims to build systems capable of perceiving, reconstructing, and generating realistic environments to support intelligent agents.
                    I received both my Master (2021) degrees from Beihang University.</a>
                </p>
                <p style="text-align:center">
                  <a href="mailto:yuhuangyue@bigai.ai">Email</a> &nbsp;/&nbsp;
                  <a href=https://scholar.google.com/citations?user=fKRgnIMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yuhuangyue/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>

              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="nexf_stop()" onmouseover="nexf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/nexf_after.jpg' width=100%>
					</div>
          <img src='images/nexf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://m-niemeyer.github.io/nexf/">
          <span class="papertitle">NExF: Learning Neural Exposure Fields for View Synthesis</span>
        </a>
        <br>
        <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
        <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
        <a href="http://www.lix.polytechnique.fr/Labo/Marie-Julie.RAKOTOSAONA/">Marie-Julie Rakotosaona</a>,
        <a href="https://moechsle.github.io">Michael Oechsle</a>,
        <a href="https://ait.ethz.ch/people/ctsalico">Christina Tsalicoglou</a>,
        <a href="https://scholar.google.com/citations?user=ml3laqEAAAAJ&hl=ja">Keisuke Tateno</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="https://federicotombari.github.io/">Federico Tombari</a>
        <br>
        <em>NeurIPS</em>, 2025
        <br>
        <a href="https://m-niemeyer.github.io/nexf/">project page</a>
        /
        <a href="https://arxiv.org/abs/2510.08279">arXiv</a>
        <p></p>
        <p>
		Learning a neural field that optimizes exposure for each 3D point enables high-quality 3D-consistent view synthesis despite extreme exposure variation during capture.
        </p>
      </td>
    </tr>
	
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr>

    <tr onmouseout="metascenes_stop()" onmouseover="metascenes_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center">
              <img src="images/metascenes.gif" class="thumbnail img-responsive" style="max-height:80px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a > -->
            <h4 class="papertitle">MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans
              </h4>
          <!-- </a> -->
          <!-- <br> -->

          <a><strong>Huangyue Yu</strong></a>,
          <a href="https://buzz-beater.github.io/">Baoxiong Jia*</a>,
          <a href="https://yixchen.github.io">Yixin Chen*</a>,
          <a href="https://yandanyang.github.io/">Yandan Yang</a>,
          <a href="https://xiaoyao-li.github.io/">Puhao Li</a>,
          <a href="https://scholar.google.com/citations?user=rY-Ndl0AAAAJ">Rongpeng Su</a>,
          <a href="https://gauleejx.github.io/">Jiaxin Li</a>,
          <a href="https://liqing-ustc.github.io/">Qing Li</a>,
          <a href="https://liangwei-bit.github.io/web/">Wei Liang</a>,
          <a href="https://zhusongchun.net/">Song-Chun Zhu</a>,
          <a href="https://tengyu.ai/">Tengyu Liu</a>,
          <a href="https://siyuanhuang.com/">Siyuan Huang</a>,


          <div class="pubcite">
              <i>
                  <font size="3">Conference on Computer Vision and Pattern Recognition (CVPR) 2025</font>
              </i>
              <!-- <i> -->
                  <!-- <font size="3">(<strong><font color="red">Highlight</font></strong>)</font> -->
              <!-- </i>  -->
              <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br>
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/CVPR2025-Conference%20Paper-green.svg">
              </label>
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label>
          </div>


          <a href="paper/metascenes.pdf">Paper</a>
          /
          <a href="https://meta-scenes.github.io/">Project</a>
          /
          <a href="https://github.com/meta-scenes/MetaScenes">Code</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>




            
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
